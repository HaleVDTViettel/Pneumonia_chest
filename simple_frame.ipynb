{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple model to know the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Pediatric Chest X-ray Pneumonia/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/thanhha/Utilities/Thanhha/ComputerVision/DAT302m/Pneumonia_chest/simple_frame.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Broot/media/thanhha/Utilities/Thanhha/ComputerVision/DAT302m/Pneumonia_chest/simple_frame.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m data_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPediatric Chest X-ray Pneumonia/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Broot/media/thanhha/Utilities/Thanhha/ComputerVision/DAT302m/Pneumonia_chest/simple_frame.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Load the datasets\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Broot/media/thanhha/Utilities/Thanhha/ComputerVision/DAT302m/Pneumonia_chest/simple_frame.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mImageFolder(data_dir\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain/\u001b[39;49m\u001b[39m\"\u001b[39;49m, transform\u001b[39m=\u001b[39;49mdata_transforms)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Broot/media/thanhha/Utilities/Thanhha/ComputerVision/DAT302m/Pneumonia_chest/simple_frame.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mImageFolder(data_dir\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest/\u001b[39m\u001b[39m\"\u001b[39m, transform\u001b[39m=\u001b[39mdata_transforms)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Broot/media/thanhha/Utilities/Thanhha/ComputerVision/DAT302m/Pneumonia_chest/simple_frame.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Create the data loaders\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    310\u001b[0m         root,\n\u001b[1;32m    311\u001b[0m         loader,\n\u001b[1;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[1;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[1;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[1;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Pediatric Chest X-ray Pneumonia/train/'"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(56, 56)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Set up the data directory\n",
    "data_dir = \"Pediatric Chest X-ray Pneumonia/\"\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = datasets.ImageFolder(data_dir+\"train/\", transform=data_transforms)\n",
    "test_dataset = datasets.ImageFolder(data_dir+\"test/\", transform=data_transforms)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Create the model and optimizer\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(3 * 56 * 56, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    " \n",
    "    print(f\"Epoch [{epoch + 1}]: Train Loss: {running_loss / len(train_loader):.4f}\")  \n",
    "\n",
    "# Evaluate the model on the test set\n",
    "correct = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {correct / len(test_dataset):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize and understand the dataset's properties, including data distribution, class imbalance, and data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_class_distribution(dataset, dataset_name):\n",
    "    class_counts = np.zeros(len(dataset.classes))\n",
    "    for _, y in dataset:\n",
    "        class_counts[y] += 1\n",
    "\n",
    "    plt.bar(dataset.classes, class_counts)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Number of images\")\n",
    "    plt.title(f\"Class distribution in the {dataset_name} dataset\")\n",
    "    plt.show()\n",
    "\n",
    "def calculate_dataset_stats(dataset):\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for x, _ in dataset:\n",
    "        mean += x.mean()\n",
    "        std += x.std()\n",
    "    \n",
    "    mean /= len(dataset)\n",
    "    std /= len(dataset)\n",
    "\n",
    "    return mean.item(), std.item()\n",
    "\n",
    "visualize_class_distribution(train_dataset, \"Train\")\n",
    "mean, std = calculate_dataset_stats(train_dataset)\n",
    "print(f\"Train dataset mean: {mean:.4f}, standard deviation: {std:.4f}\")\n",
    "\n",
    "visualize_class_distribution(test_dataset, \"Test\")\n",
    "mean, std = calculate_dataset_stats(test_dataset)\n",
    "print(f\"Test dataset mean: {mean:.4f}, standard deviation: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate F1 score\n",
    "F1 score is mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize empty lists to store true labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "correct = 0\n",
    "\n",
    "# Accumulate true labels and predictions for all mini-batches in the test set\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_labels.extend(labels.numpy())\n",
    "        predicted_labels.extend(predicted.numpy())\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {correct / len(test_dataset):.2%}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score using the accumulated true labels and predictions\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "A confusion matrix is a table that displays the number of true positives, true negatives, false positives, and false negatives for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix using the accumulated true labels and predictions\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Pneumonia\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the confusion matrix you provided, we can make the following observations about the model**\n",
    "\n",
    "`1. High sensitivity (Recall) for the Pneumonia class:`\n",
    "The model is able to correctly identify a large majority of pneumonia cases **(385 out of 390)**, meaning that it has a high true positive rate for the Pneumonia class. This is important in medical applications, as you would want the model to have a low false negative rate, which could lead to missed diagnoses.\n",
    "\n",
    "`2. Lower precision for the Normal class:`\n",
    "The model incorrectly classifies a significant number of normal images as pneumonia **(162 out of 234)**. This means that the precision for the Normal class is relatively low. In a medical context, this would lead to a higher false positive rate, which could result in unnecessary further testing or treatment for patients who do not have pneumonia.\n",
    "\n",
    "`3. Imbalanced classification:`\n",
    "The model performs better in identifying the Pneumonia class than the Normal class. This could be due to class imbalance in the dataset, where there might be more Pneumonia images than Normal images. This can lead the model to be biased towards the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "from modules.check_solution import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(\"modules/h.yaml\", \"r\") as file:\n",
    "    h = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "\n",
    "f1_array = np.array([])\n",
    "accuracy_array = np.array([])\n",
    "start_time = time.time()\n",
    "\n",
    "repeats = 5\n",
    "for i in range(repeats):\n",
    "    print(\"===============================================\")\n",
    "    print(f\"Running solution {i+1}/{repeats}\")\n",
    "    f1, accuracy = check_solution(h, verbose=(i==0))\n",
    "    print(f\"F1 = {f1:.2f}, accuracy = {accuracy:.2f} \")\n",
    "    f1_array = np.append(f1_array, f1)\n",
    "    accuracy_array = np.append(accuracy_array, accuracy) \n",
    "\n",
    "# Calculate elapsed time and remaining time\n",
    "repeat_time = (time.time() - start_time) / repeats\n",
    "repeat_time_min, repeat_time_sec = divmod(repeat_time, 60)\n",
    "\n",
    "# Printing final results\n",
    "print(\"Results\")\n",
    "print(f\"F1: {np.mean(f1_array):.1%} (+-{np.std(f1_array):.1%})\")\n",
    "print(f\"Accuracy: {np.mean(accuracy_array):.1%} (+-{np.std(accuracy_array):.1%})\")\n",
    "print(f\"Time of one solution: {repeat_time_min:.0f}m {repeat_time_sec:.0f}s\")\n",
    "print(f\" | {np.mean(f1_array):.1%} (+-{np.std(f1_array):.1%}) | {np.mean(accuracy_array):.1%} (+-{np.std(accuracy_array):.1%}) | {repeat_time_min:.0f}m {repeat_time_sec:.0f}s\")\n",
    "\n",
    "# Print hyperparameters for reminding what the final data is for\n",
    "print(\"Hyperparameters:\")\n",
    "pprint.pprint(h, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
